<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://Squid-dot.github.io</id>
    <title>Iktsuarpok</title>
    <updated>2020-05-09T06:53:56.894Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://Squid-dot.github.io"/>
    <link rel="self" href="https://Squid-dot.github.io/atom.xml"/>
    <subtitle>个人学习笔记</subtitle>
    <logo>https://Squid-dot.github.io/images/avatar.png</logo>
    <icon>https://Squid-dot.github.io/favicon.ico</icon>
    <rights>All rights reserved 2020, Iktsuarpok</rights>
    <entry>
        <title type="html"><![CDATA[MyBatis-Plus]]></title>
        <id>https://Squid-dot.github.io/post/mybatis-plus/</id>
        <link href="https://Squid-dot.github.io/post/mybatis-plus/">
        </link>
        <updated>2020-03-29T10:46:58.000Z</updated>
        <content type="html"><![CDATA[<h1 id="mybatis-plus">MyBatis-Plus</h1>
<h2 id="mybatis-plus概述">MyBatis-Plus概述</h2>
<blockquote>
<p>简介</p>
</blockquote>
<p>MyBatis-Plus（简称 MP）是一个 MyBatis 的增强工具，在 MyBatis 的基础上只做增强不做改变，为简化开发、提高效率而生。</p>
<p><a href="https://mp.baomidou.com/">官网</a></p>
<blockquote>
<p>特性</p>
</blockquote>
<ul>
<li><strong>无侵入</strong>：只做增强不做改变，引入它不会对现有工程产生影响，如丝般顺滑</li>
<li><strong>损耗小</strong>：启动即会自动注入基本 CURD，性能基本无损耗，直接面向对象操作</li>
<li><strong>强大的 CRUD 操作</strong>：内置通用 Mapper、通用 Service，仅仅通过少量配置即可实现单表大部分 CRUD 操作，更有强大的条件构造器，满足各类使用需求</li>
<li><strong>支持 Lambda 形式调用</strong>：通过 Lambda 表达式，方便的编写各类查询条件，无需再担心字段写错</li>
<li><strong>支持主键自动生成</strong>：支持多达 4 种主键策略（内含分布式唯一 ID 生成器 - Sequence），可自由配置，完美解决主键问题</li>
<li><strong>支持 ActiveRecord 模式</strong>：支持 ActiveRecord 形式调用，实体类只需继承 Model 类即可进行强大的 CRUD 操作</li>
<li><strong>支持自定义全局通用操作</strong>：支持全局通用方法注入（ Write once, use anywhere ）</li>
<li><strong>内置代码生成器</strong>：采用代码或者 Maven 插件可快速生成 Mapper 、 Model 、 Service 、 Controller 层代码，支持模板引擎，更有超多自定义配置等您来使用</li>
<li><strong>内置分页插件</strong>：基于 MyBatis 物理分页，开发者无需关心具体操作，配置好插件之后，写分页等同于普通 List 查询</li>
<li><strong>分页插件支持多种数据库</strong>：支持 MySQL、MariaDB、Oracle、DB2、H2、HSQL、SQLite、Postgre、SQLServer 等多种数据库</li>
<li><strong>内置性能分析插件</strong>：可输出 Sql 语句以及其执行时间，建议开发测试时启用该功能，能快速揪出慢查询</li>
<li><strong>内置全局拦截插件</strong>：提供全表 delete 、 update 操作智能分析阻断，也可自定义拦截规则，预防误操作</li>
</ul>
<hr>
<h2 id="快速开始举例">快速开始举例</h2>
<p>快速开始：<a href="%5Bhttps://mp.baomidou.com/guide/quick-start.html#%E5%88%9D%E5%A7%8B%E5%8C%96%E5%B7%A5%E7%A8%8B%5D(https://mp.baomidou.com/guide/quick-start.html#%E5%88%9D%E5%A7%8B%E5%8C%96%E5%B7%A5%E7%A8%8B)">初始化工程</a></p>
<blockquote>
<p>步骤</p>
</blockquote>
<ol>
<li>创建数据库<code>mybatis_plus</code></li>
<li>创建表<code>User</code>并添加数据</li>
</ol>
<pre><code class="language-sql">-- 建立表
DROP TABLE IF EXISTS user;
CREATE TABLE user
(
	id BIGINT(20) NOT NULL COMMENT '主键ID',
	name VARCHAR(30) NULL DEFAULT NULL COMMENT '姓名',
	age INT(11) NULL DEFAULT NULL COMMENT '年龄',
	email VARCHAR(50) NULL DEFAULT NULL COMMENT '邮箱',
	PRIMARY KEY (id)
);

-- 添加数据
DELETE FROM user;
INSERT INTO user (id, name, age, email) VALUES
(1, 'Jone', 18, 'test1@baomidou.com'),
(2, 'Jack', 20, 'test2@baomidou.com'),
(3, 'Tom', 28, 'test3@baomidou.com'),
(4, 'Sandy', 21, 'test4@baomidou.com'),
(5, 'Billie', 24, 'test5@baomidou.com');
</code></pre>
<ol start="3">
<li>引入所需依赖</li>
</ol>
<p><a href="https://mp.baomidou.com/guide/install.html#release">所需依赖地址</a></p>
<pre><code class="language-java">        &lt;!-- 数据库驱动 --&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;mysql&lt;/groupId&gt;
            &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;
        &lt;/dependency&gt;

        &lt;!-- lombok --&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.projectlombok&lt;/groupId&gt;
            &lt;artifactId&gt;lombok&lt;/artifactId&gt;
            &lt;version&gt;1.18.10&lt;/version&gt;
        &lt;/dependency&gt;

        &lt;!-- MyBatis-Plus --&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;com.baomidou&lt;/groupId&gt;
            &lt;artifactId&gt;mybatis-plus-boot-starter&lt;/artifactId&gt;
            &lt;version&gt;3.3.1.tmp&lt;/version&gt;
        &lt;/dependency&gt;
</code></pre>
<ol start="4">
<li>配置</li>
</ol>
<pre><code class="language-yaml">spring:
  datasource:
    driver-class-name: com.mysql.jdbc.Driver
    url: jdbc:mysql://localhost:3306/
    username: root
    password: 123456
</code></pre>
<ol start="5">
<li>编码</li>
</ol>
<ul>
<li>仅需要在对应的<code>mapper</code>上继承自<code>BaseMapper&lt;type&gt;</code>接口即可使用</li>
</ul>
<pre><code class="language-javascript">//实体类
@Data
@AllArgsConstructor
@NoArgsConstructor
public class User {
    private Long id;
    private String name;
    private Integer age;
    private String email;
}
</code></pre>
<pre><code class="language-java">//Mapper接口
@Repository
public interface UserMapper extends BaseMapper&lt;User&gt; {
    //如此，所有的CRUD操作已经自动编写完成
}

</code></pre>
<pre><code>//启动类（添加MapperScan）
@MapperScan(&quot;com.squid.mapper&quot;)
@SpringBootApplication
public class MybatisPlusApplication {

    public static void main(String[] args) {
        SpringApplication.run(MybatisPlusApplication.class, args);
    }

}
</code></pre>
<ol start="6">
<li>开始使用</li>
</ol>
<pre><code class="language-java">@SpringBootTest
class MybatisPlusApplicationTests {

    @Autowired
    private UserMapper userMapper;

    @Test
    void contextLoads() {
        List&lt;User&gt; users = userMapper.selectList(null);
        users.forEach(System.out::println);
    }

}
</code></pre>
<blockquote>
<p>UserMapper 中的 <code>selectList()</code> 方法的参数为 MP 内置的条件封装器 <code>Wrapper</code>，所以不填写就是无任何条件</p>
</blockquote>
<p>控制台输出：</p>
<pre><code>User(id=1, name=Jone, age=18, email=test1@baomidou.com)
User(id=2, name=Jack, age=20, email=test2@baomidou.com)
User(id=3, name=Tom, age=28, email=test3@baomidou.com)
User(id=4, name=Sandy, age=21, email=test4@baomidou.com)
User(id=5, name=Billie, age=24, email=test5@baomidou.com)
</code></pre>
<p><strong>小结：</strong></p>
<p>通过以上几个步骤，便可以实现简单的CRUD操作，并且不用编写XML文件。</p>
<p>从以上步骤中，可以看到集成<code>MyBatis-Plus</code>，只需要引入 starter 工程，并配置 mapper 扫描路径即可。</p>
<hr>
<h2 id="日志配置">日志配置</h2>
<blockquote>
<p>在配置文件中添加如下</p>
</blockquote>
<pre><code>mybatis-plus:
  configuration:
    log-impl: org.apache.ibatis.logging.stdout.StdOutImpl

</code></pre>
<p>如上方式采用了默认日志，使用后控制台输出如下：</p>
<pre><code>Creating a new SqlSession
SqlSession [org.apache.ibatis.session.defaults.DefaultSqlSession@5984feef] was not registered for synchronization because synchronization is not active
JDBC Connection [HikariProxyConnection@345703799 wrapping com.mysql.cj.jdbc.ConnectionImpl@5740ff5e] will not be managed by Spring
==&gt;  Preparing: SELECT id,name,age,email FROM user 
==&gt; Parameters: 
&lt;==    Columns: id, name, age, email
&lt;==        Row: 1, Jone, 18, test1@baomidou.com
&lt;==        Row: 2, Jack, 20, test2@baomidou.com
&lt;==        Row: 3, Tom, 28, test3@baomidou.com
&lt;==        Row: 4, Sandy, 21, test4@baomidou.com
&lt;==        Row: 5, Billie, 24, test5@baomidou.com
&lt;==      Total: 5

</code></pre>
<p>可以看到，进行了JDBC连接，并且采用了<code>Hikari</code>数据源，并且自动生成了查询全部<code>User</code>的sql语句。</p>
<p><strong>小结：</strong></p>
<p>配置了日志后，可以更方便的查看到具体运行情况，便于个人学习。</p>
<hr>
<h2 id="注解">注解</h2>
<blockquote>
<p>简介</p>
</blockquote>
<p>使用MyBatis-Plus时需要使用到注解功能，相关可以查阅<a href="https://mp.baomidou.com/guide/annotation.html">注解</a></p>
<hr>
<h2 id="crud接口">CRUD接口</h2>
<h3 id="mapper-crud接口">Mapper CRUD接口</h3>
<blockquote>
<p>说明</p>
</blockquote>
<ul>
<li>通用 CRUD 封装<code>BaseMapper</code>接口，为 <code>Mybatis-Plus</code> 启动时自动解析实体表关系映射转换为 <code>Mybatis</code> 内部对象注入容器</li>
<li>泛型 <code>T</code> 为任意实体对象</li>
<li>参数 <code>Serializable</code> 为任意类型主键 <code>Mybatis-Plus</code> 不推荐使用复合主键约定每一张表都有自己的唯一 <code>id</code> 主键</li>
<li>对象 <code>Wrapper</code> 为条件构造器</li>
</ul>
<p>使用CRUD操作时，仅需使用继承自<code>BaseMapper</code>接口的接口，调用如下方法即可。</p>
<h4 id="insert">Insert</h4>
<pre><code class="language-java">// 插入一条记录
int insert(T entity);

</code></pre>
<p><strong>可以通过 @TableId 注解进行主键注解</strong></p>
<h5 id="参数说明">参数说明</h5>
<table>
<thead>
<tr>
<th style="text-align:center">类型</th>
<th style="text-align:center">参数名</th>
<th style="text-align:center">描述</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">T</td>
<td style="text-align:center">entity</td>
<td style="text-align:center">实体对象</td>
</tr>
</tbody>
</table>
<h5 id="主键生成算法-雪花算法">主键生成算法--雪花算法</h5>
<p><a href="https://www.cnblogs.com/pangguoming/p/8064549.html">分布式系统唯一ID生成方案汇总</a></p>
<p>当插入时如果未给出ID，将会使用雪花算法生成。</p>
<blockquote>
<p>雪花算法</p>
</blockquote>
<p>snowflake是Twitter开源的分布式ID生成算法，结果是一个long型的ID。其核心思想是：使用41bit作为毫秒数，10bit作为机器的ID（5个bit是数据中心，5个bit的机器ID），12bit作为毫秒内的流水号（意味着每个节点在每毫秒可以产生 4096 个 ID），最后还有一个符号位，永远是0。 可以保证几乎全球唯一。</p>
<h4 id="delete">Delete</h4>
<pre><code class="language-java">// 根据 entity 条件，删除记录
int delete(@Param(Constants.WRAPPER) Wrapper&lt;T&gt; wrapper);
// 删除（根据ID 批量删除）
int deleteBatchIds(@Param(Constants.COLLECTION) Collection&lt;? extends Serializable&gt; idList);
// 根据 ID 删除
int deleteById(Serializable id);
// 根据 columnMap 条件，删除记录
int deleteByMap(@Param(Constants.COLUMN_MAP) Map&lt;String, Object&gt; columnMap);

</code></pre>
<h5 id="参数说明-2">参数说明</h5>
<table>
<thead>
<tr>
<th style="text-align:center">类型</th>
<th style="text-align:center">参数名</th>
<th style="text-align:center">描述</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">Wrapper<T></td>
<td style="text-align:center">wrapper</td>
<td style="text-align:center">实体对象封装操作类（可以为 null）</td>
</tr>
<tr>
<td style="text-align:center">Collection&lt;? extends Serializable&gt;</td>
<td style="text-align:center">idList</td>
<td style="text-align:center">主键ID列表(不能为 null 以及 empty)</td>
</tr>
<tr>
<td style="text-align:center">Serializable</td>
<td style="text-align:center">id</td>
<td style="text-align:center">主键ID</td>
</tr>
<tr>
<td style="text-align:center">Map&lt;String, Object&gt;</td>
<td style="text-align:center">columnMap</td>
<td style="text-align:center">表字段 map 对象</td>
</tr>
</tbody>
</table>
<h4 id="update">Update</h4>
<pre><code class="language-java">// 根据 whereEntity 条件，更新记录
int update(@Param(Constants.ENTITY) T entity, @Param(Constants.WRAPPER) Wrapper&lt;T&gt; updateWrapper);
// 根据 ID 修改
int updateById(@Param(Constants.ENTITY) T entity);

</code></pre>
<h5 id="参数说明-3">参数说明</h5>
<table>
<thead>
<tr>
<th style="text-align:center">类型</th>
<th style="text-align:center">参数名</th>
<th style="text-align:center">描述</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">T</td>
<td style="text-align:center">entity</td>
<td style="text-align:center">实体对象 (set 条件值,可为 null)</td>
</tr>
<tr>
<td style="text-align:center">Wrapper<T></td>
<td style="text-align:center">updateWrapper</td>
<td style="text-align:center">实体对象封装操作类（可以为 null,里面的 entity 用于生成 where 语句）</td>
</tr>
</tbody>
</table>
<h4 id="select">Select</h4>
<pre><code class="language-java">// 根据 ID 查询
T selectById(Serializable id);
// 根据 entity 条件，查询一条记录
T selectOne(@Param(Constants.WRAPPER) Wrapper&lt;T&gt; queryWrapper);

// 查询（根据ID 批量查询）
List&lt;T&gt; selectBatchIds(@Param(Constants.COLLECTION) Collection&lt;? extends Serializable&gt; idList);
// 根据 entity 条件，查询全部记录
List&lt;T&gt; selectList(@Param(Constants.WRAPPER) Wrapper&lt;T&gt; queryWrapper);
// 查询（根据 columnMap 条件）
List&lt;T&gt; selectByMap(@Param(Constants.COLUMN_MAP) Map&lt;String, Object&gt; columnMap);
// 根据 Wrapper 条件，查询全部记录
List&lt;Map&lt;String, Object&gt;&gt; selectMaps(@Param(Constants.WRAPPER) Wrapper&lt;T&gt; queryWrapper);
// 根据 Wrapper 条件，查询全部记录。注意： 只返回第一个字段的值
List&lt;Object&gt; selectObjs(@Param(Constants.WRAPPER) Wrapper&lt;T&gt; queryWrapper);

// 根据 entity 条件，查询全部记录（并翻页）
IPage&lt;T&gt; selectPage(IPage&lt;T&gt; page, @Param(Constants.WRAPPER) Wrapper&lt;T&gt; queryWrapper);
// 根据 Wrapper 条件，查询全部记录（并翻页）
IPage&lt;Map&lt;String, Object&gt;&gt; selectMapsPage(IPage&lt;T&gt; page, @Param(Constants.WRAPPER) Wrapper&lt;T&gt; queryWrapper);
// 根据 Wrapper 条件，查询总记录数
Integer selectCount(@Param(Constants.WRAPPER) Wrapper&lt;T&gt; queryWrapper);

</code></pre>
<h5 id="参数说明-4">参数说明</h5>
<table>
<thead>
<tr>
<th style="text-align:center">类型</th>
<th style="text-align:center">参数名</th>
<th style="text-align:center">描述</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">Serializable</td>
<td style="text-align:center">id</td>
<td style="text-align:center">主键ID</td>
</tr>
<tr>
<td style="text-align:center">Wrapper<T></td>
<td style="text-align:center">queryWrapper</td>
<td style="text-align:center">实体对象封装操作类（可以为 null）</td>
</tr>
<tr>
<td style="text-align:center">Collection&lt;? extends Serializable&gt;</td>
<td style="text-align:center">idList</td>
<td style="text-align:center">主键ID列表(不能为 null 以及 empty)</td>
</tr>
<tr>
<td style="text-align:center">Map&lt;String, Object&gt;</td>
<td style="text-align:center">columnMap</td>
<td style="text-align:center">表字段 map 对象</td>
</tr>
<tr>
<td style="text-align:center">IPage<T></td>
<td style="text-align:center">page</td>
<td style="text-align:center">分页查询条件（可以为 RowBounds.DEFAULT）</td>
</tr>
</tbody>
</table>
<hr>
<h2 id="条件构造器">条件构造器</h2>
<blockquote>
<p>作用</p>
</blockquote>
<p>用于查询时对于条件选择的添加，具体参考<a href="https://mp.baomidou.com/guide/wrapper.html#abstractwrapper">文档-条件构造器</a></p>
<h5 id="条件构造器的使用">条件构造器的使用</h5>
<pre><code class="language-java">QueryWrapper&lt;User&gt; wrapper = new QueryWrapper&lt;&gt;();
wrapper.isNotNull(&quot;name&quot;)           //名字不为空
    .ge(&quot;age&quot;,12);          //年龄大于等于12
userMapper.selectList(wrapper);

</code></pre>
<hr>
<h2 id="代码生成器">代码生成器</h2>
<blockquote>
<p>作用</p>
</blockquote>
<p>用于自动生成各层之间的代码</p>
<blockquote>
<p>使用方式</p>
</blockquote>
<pre><code class="language-java">//构建一个代码自动生成器对象、
AutoGenerator generator = new AutoGenerator();
generator.setTemplateEngine(new FreemarkerTemplateEngine());//选择模板引擎，可以自定义

//配置策略
//1.全局配置
GlobalConfig globalConfig = new GlobalConfig();
globalConfig.setOutputDir(System.getProperty(&quot;user.dir&quot;) + &quot;/src/main/java&quot;);
globalConfig.setAuthor(&quot;Squid&quot;);
globalConfig.setOpen(false);
globalConfig.setFileOverride(false);
globalConfig.setSwagger2(true);

//2.设置数据源
DataSourceConfig dataSourceConfig = new DataSourceConfig();
dataSourceConfig.setUrl(&quot;jdbc:mysql://localhost:3306/ant?useUnicode=true&amp;useSSL=false&amp;characterEncoding=utf8&quot;);
dataSourceConfig.setDriverName(&quot;com.mysql.jdbc.Driver&quot;);
dataSourceConfig.setUsername(&quot;root&quot;);
dataSourceConfig.setPassword(&quot;password&quot;);
dataSourceConfig.setDbType(DbType.MYSQL);
generator.setDataSource(dataSourceConfig);

//3.包配置
PackageConfig pc = new PackageConfig();
pc.setModuleName(&quot;blog&quot;);
pc.setParent(&quot;com.squid&quot;);
pc.setEntity(&quot;entity&quot;);
pc.setMapper(&quot;mapper&quot;);
pc.setService(&quot;service&quot;);
pc.setController(&quot;controller&quot;);
generator.setPackageInfo(pc);

//4.策略配置
StrategyConfig strategy = new StrategyConfig();
strategy.setInclude(&quot;user&quot;);
strategy.setNaming(NamingStrategy.underline_to_camel);
strategy.setColumnNaming(NamingStrategy.underline_to_camel);
strategy.setEntityLombokModel(true);
strategy.setLogicDeleteFieldName(&quot;deleted&quot;);
	//自动填充
TableFill gmtCreate = new TableFill(&quot;gmt_create&quot;,FieldFill.INSERT);
TableFill gmtUpdate = new TableFill(&quot;gmt_update&quot;,FieldFill.INSERT_UPDATE);
ArrayList&lt;TableFill&gt; tableFills = new ArrayList&lt;&gt;();
tableFills.add(gmtCreate);
tableFills.add(gmtUpdate);
strategy.setTableFillList(tableFills);
	//乐观锁
strategy.setVersionFieldName(&quot;version&quot;);
generator.setStrategy(strategy);
generator.execute();	//执行

</code></pre>
<hr>
<h2 id="扩展插件">扩展插件</h2>
<h5 id="自动填充功能">自动填充功能</h5>
<blockquote>
<p>说明</p>
</blockquote>
<p>该功能适用于 Insert 操作和 Update 操作。通过 实现元对象处理器接口：com.baomidou.mybatisplus.core.handlers.MetaObjectHandler 来实现对于添加、更新操作的自动填充。</p>
<blockquote>
<p>示例</p>
</blockquote>
<ul>
<li>注解填充字段</li>
</ul>
<pre><code class="language-java">@Data
@AllArgsConstructor
@NoArgsConstructor
public class User {
    private Long id;
    private String name;
    private Integer age;
    private String email;
    @TableField(fill = FieldFill.INSERT)    //填充字段 添加
    private Date gmtCreate;
    @TableField(fill = FieldFill.INSERT_UPDATE) //填充字段 添加与更新
    private Date gmtModify;
}

</code></pre>
<ul>
<li>实现自定义类</li>
</ul>
<pre><code class="language-java">@Component  //需要添加至IOC容器中
public class MyMetaObjectHandler implements MetaObjectHandler {
    //插入时的填充策略
    @Override
    public void insertFill(MetaObject metaObject) {
        this.setFieldValByName(&quot;gmtCreate&quot;,new Date(),metaObject);
        this.setFieldValByName(&quot;gmtModify&quot;,new Date(),metaObject);
    }

    //更新时的填充策略
    @Override
    public void updateFill(MetaObject metaObject) {
        this.setFieldValByName(&quot;gmtModify&quot;,new Date(),metaObject);
    }
}

</code></pre>
<h5 id="乐观锁插件">乐观锁插件</h5>
<blockquote>
<p>乐观锁简介</p>
</blockquote>
<p>顾名思义，非常乐观，不论做什么都认为不会出现问题，因此不论做什么都不会上锁。</p>
<blockquote>
<p>乐观锁的实现方式</p>
</blockquote>
<ul>
<li>取出记录时，获取当前的version</li>
<li>执行更新时，set version = newVersion where version = oldVersion</li>
<li>如果 version != oldVersion 则更新失败</li>
</ul>
<blockquote>
<p>乐观锁插件</p>
</blockquote>
<ol>
<li>在对应的实体类字段中添加注解</li>
</ol>
<pre><code class="language-java">@Version
private Integer version;

</code></pre>
<p><strong>特别说明:</strong></p>
<p><strong>支持的数据类型只有:int,Integer,long,Long,Date,Timestamp,LocalDateTime</strong></p>
<p>整数类型下 <code>newVersion = oldVersion + 1</code></p>
<p><code>newVersion</code> 会回写到 <code>entity</code> 中</p>
<p>仅支持 <code>updateById(id)</code> 与 <code>update(entity, wrapper)</code> 方法</p>
<p><strong>在 <code>update(entity, wrapper)</code> 方法下, <code>wrapper</code> 不能复用!!!</strong></p>
<ol start="2">
<li>配置插件</li>
</ol>
<p>spring xml:</p>
<pre><code class="language-xml">&lt;bean class=&quot;com.baomidou.mybatisplus.extension.plugins.OptimisticLockerInterceptor&quot;/&gt;

</code></pre>
<p>spring boot:</p>
<pre><code class="language-java">@Bean
public OptimisticLockerInterceptor optimisticLockerInterceptor() {
    return new OptimisticLockerInterceptor();
}

</code></pre>
<p><strong>示例：</strong></p>
<pre><code class="language-java">@Configuration
@MapperScan(&quot;com.squid.mapper&quot;)
@EnableTransactionManagement
public class MyBatisPlusConfig {
    @Bean
    public OptimisticLockerInterceptor optimisticLockerInterceptor() {
        return new OptimisticLockerInterceptor();
    }
}


</code></pre>
<h5 id="分页插件">分页插件</h5>
<blockquote>
<p>作用</p>
</blockquote>
<p>实现分页查询效果</p>
<blockquote>
<p>使用方式</p>
</blockquote>
<ol>
<li>配置插件</li>
</ol>
<p>spring xml:</p>
<pre><code class="language-xml">&lt;property name=&quot;plugins&quot;&gt;
    &lt;array&gt;
        &lt;bean class=&quot;com.baomidou.mybatisplus.extension.plugins.PaginationInterceptor&quot;&gt;
            &lt;property name=&quot;sqlParser&quot; ref=&quot;自定义解析类、可以没有&quot;/&gt;
            &lt;property name=&quot;dialectClazz&quot; value=&quot;自定义方言类、可以没有&quot;/&gt;
            &lt;!-- COUNT SQL 解析.可以没有 --&gt;
            &lt;property name=&quot;countSqlParser&quot; ref=&quot;countSqlParser&quot;/&gt;
        &lt;/bean&gt;
    &lt;/array&gt;
&lt;/property&gt;

&lt;bean id=&quot;countSqlParser&quot; class=&quot;com.baomidou.mybatisplus.extension.plugins.pagination.optimize.JsqlParserCountOptimize&quot;&gt;
    &lt;!-- 设置为 true 可以优化部分 left join 的sql --&gt;
    &lt;property name=&quot;optimizeJoin&quot; value=&quot;true&quot;/&gt;
&lt;/bean&gt;

</code></pre>
<p>Springboot方式：</p>
<pre><code class="language-java">@Bean
    public PaginationInterceptor paginationInterceptor() {
        PaginationInterceptor paginationInterceptor = new PaginationInterceptor();
        // 设置请求的页面大于最大页后操作， true调回到首页，false 继续请求  默认false
        // paginationInterceptor.setOverflow(false);
        // 设置最大单页限制数量，默认 500 条，-1 不受限制
        // paginationInterceptor.setLimit(500);
        // 开启 count 的 join 优化,只针对部分 left join
        paginationInterceptor.setCountSqlParser(new JsqlParserCountOptimize(true));
        return paginationInterceptor;
    }

</code></pre>
<ol start="2">
<li>使用</li>
</ol>
<p>spring方式：</p>
<pre><code class="language-xml">&lt;select id=&quot;selectPageVo&quot; resultType=&quot;com.baomidou.cloud.entity.UserVo&quot;&gt;
    SELECT id,name FROM user WHERE state=#{state}
&lt;/select&gt;

</code></pre>
<p>springboot方式：</p>
<pre><code class="language-java">Page&lt;User&gt; page = new Page&lt;&gt;(2,5);
userMapper.selectPage(page,null);
page.getRecords().forEach(System.out::println);

</code></pre>
<h5 id="逻辑删除组件">逻辑删除组件</h5>
<blockquote>
<p>作用</p>
</blockquote>
<p>在数据库中定义的标识，例如flag，当flag = 0时认为未删除，查询时显示，flag = 1时则显示</p>
<blockquote>
<p>使用方式</p>
</blockquote>
<ul>
<li>application.yml 加入配置(如果默认值和mp默认的一样,该配置可无):</li>
</ul>
<pre><code class="language-yml">mybatis-plus:
  global-config:
    db-config:
      logic-delete-field: flag  #全局逻辑删除字段值 3.3.0开始支持，详情看下面。
      logic-delete-value: 1 # 逻辑已删除值(默认为 1)
      logic-not-delete-value: 0 # 逻辑未删除值(默认为 0)

</code></pre>
<ul>
<li>配置类中添加 Bean(3.1.1开始不再需要这一步)：</li>
</ul>
<pre><code class="language-java"> 	@Bean
    public ISqlInjector sqlInjector() {
        return new LogicSqlInjector();
    }

</code></pre>
<ul>
<li>
<p>实体类字段上加上<code>@TableLogic</code>注解</p>
<pre><code class="language-java">@TableLogic
private Integer deleted;

</code></pre>
</li>
<li>
<p>全局逻辑删除: 3.3.0开始支持</p>
</li>
</ul>
<p>如果公司代码比较规范，比如统一了全局都是flag为逻辑删除字段。</p>
<p>使用此配置则不需要在实体类上添加 @TableLogic。</p>
<p>但如果实体类上有 @TableLogic 则以实体上的为准，忽略全局。 即先查找注解再查找全局，都没有则此表没有逻辑删除。</p>
<pre><code class="language-yaml">mybatis-plus:
  global-config:
    db-config:
      logic-delete-field: flag  #全局逻辑删除字段值

</code></pre>
<h5 id="性能分析插件">性能分析插件</h5>
<blockquote>
<p>作用</p>
</blockquote>
<p>用于输出每条 SQL 语句及其执行时间</p>
<blockquote>
<p>使用方式</p>
</blockquote>
<p>spring使用方式：</p>
<pre><code class="language-xml">&lt;!-- SQL 执行性能分析，开发环境使用，线上不推荐。 maxTime 指的是 sql 最大执行时长 --&gt;
&lt;plugin interceptor=&quot;com.baomidou.mybatisplus.extension.plugins.PerformanceInterceptor&quot;&gt;
    &lt;property name=&quot;maxTime&quot; value=&quot;100&quot; /&gt;
    &lt;!--SQL是否格式化 默认false--&gt;
    &lt;property name=&quot;format&quot; value=&quot;true&quot; /&gt;
&lt;/plugin&gt;
</code></pre>
<p>springboot方式：</p>
<pre><code class="language-java">@Bean
@Profile({&quot;dev&quot;,&quot;test&quot;})
public PerformanceInterceptor performanceInterceptor(){
    PerformanceInterceptor performanceInterceptor = new PerformanceInterceptor();
    performanceInterceptor.setMaxTime(1);
    performanceInterceptor.setFormat(true);
    //....
    return performanceInterceptor;
}
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Redis集群]]></title>
        <id>https://Squid-dot.github.io/post/redis-ji-qun/</id>
        <link href="https://Squid-dot.github.io/post/redis-ji-qun/">
        </link>
        <updated>2020-03-06T13:18:19.000Z</updated>
        <content type="html"><![CDATA[<h1 id="redis集群">Redis集群</h1>
<h2 id="主从复制">主从复制</h2>
<p><a href="https://www.cnblogs.com/wade-luffy/p/9639986.html">相关文档</a></p>
<blockquote>
<p>简介</p>
</blockquote>
<p>主从复制，是指将一台Redis服务器的数据，复制到其他的Redis服务器。前者称为主节点(master/leader)，后者称为从节点(slave/follower)；数据的复制是单向的，只能由主节点到从节点。</p>
<p>主从复制的作用主要包括：</p>
<ol>
<li>数据冗余：主从复制实现了数据的热备份，是持久化之外的一种数据冗余方式。</li>
<li>故障恢复：当主节点出现问题时，可以由从节点提供服务，实现快速的故障恢复；实际上是一种服务的冗余。</li>
<li>负载均衡：在主从复制的基础上，配合读写分离，可以由主节点提供写服务，由从节点提供读服务（即写Redis数据时应用连接主节点，读Redis数据时应用连接从节点），分担服务器负载；尤其是在写少读多的场景下，通过多个从节点分担读负载，可以大大提高Redis服务器的并发量。</li>
<li>高可用基石：除了上述作用以外，主从复制还是哨兵和集群能够实施的基础，因此说主从复制是Redis高可用的基础。</li>
</ol>
<hr>
<h3 id="工作流程">工作流程</h3>
<p>主从复制过程大体可以分为三个阶段：</p>
<ol>
<li>建立连接阶段（即准备阶段）</li>
<li>数据同步阶段</li>
<li>命令传播阶段</li>
</ol>
<figure data-type="image" tabindex="1"><img src="E:%5CTypora%5CNotes%5C%E6%95%B0%E6%8D%AE%E5%BA%93%5CRedis%5CRedis%E9%9B%86%E7%BE%A4.assets%5Cimage-20200306204513274.png" alt="image-20200306204513274" loading="lazy"></figure>
<h4 id="阶段1建立连接阶段工作流程">阶段1：建立连接阶段工作流程</h4>
<p>步骤：</p>
<ol>
<li>slave端设置master的地址与端口，通过slaveof ip port与master相互连接，在slave端保存master相应的信息</li>
<li>建立socket连接，用于master与slave端传递信息</li>
<li>slave周期性的对master发送ping命令（定时器任务），保证master在线</li>
<li>如果master设置了密码，进行身份验证</li>
<li>slave将端口信息发送给master，master保存slave的端口信息</li>
</ol>
<p>状态：</p>
<ul>
<li>slave：保存master的地址与端口</li>
<li>master：保存slave的端口</li>
</ul>
<p>总体：之间创建了连接的socket</p>
<figure data-type="image" tabindex="2"><img src="E:%5CTypora%5CNotes%5C%E6%95%B0%E6%8D%AE%E5%BA%93%5CRedis%5CRedis%E9%9B%86%E7%BE%A4.assets%5Cimage-20200306210130500.png" alt="" loading="lazy"></figure>
<blockquote>
<p>主从连接方式</p>
</blockquote>
<p>方式一：客户端发送指令</p>
<pre><code>slaveof &lt;masterip&gt; &lt;masterport&gt;
</code></pre>
<p>方式二：启动服务器时携带参数</p>
<pre><code>redis-server --slaveof &lt;masterip&gt; &lt;masterport&gt;
</code></pre>
<p>方式三：服务器配置*</p>
<pre><code>slaveof &lt;masterip&gt; &lt;masterport&gt;
</code></pre>
<p>断开连接方式：</p>
<pre><code>slaveof no one
</code></pre>
<hr>
<h4 id="阶段2数据同步阶段工作流程">阶段2：数据同步阶段工作流程</h4>
<p>步骤：</p>
<ol>
<li>slave发送psync2指令，请求master同步数据</li>
<li>master创建RDB同步数据</li>
<li>slave恢复RDB同步数据</li>
<li>slave向master请求部分同步数据</li>
<li>slave恢复部分同步数据</li>
</ol>
<p>状态：</p>
<ul>
<li>slave：具有master端全部数据，包括RDB过程接收的数据</li>
<li>master：保存slave当前数据同步的位置</li>
</ul>
<p>总体：之间完成了数据克隆</p>
<figure data-type="image" tabindex="3"><img src="E:%5CTypora%5CNotes%5C%E6%95%B0%E6%8D%AE%E5%BA%93%5CRedis%5CRedis%E9%9B%86%E7%BE%A4.assets%5Cimage-20200306211502117.png" alt="" loading="lazy"></figure>
<blockquote>
<p>说明</p>
</blockquote>
<p>master：</p>
<ol>
<li>如果master数据量巨大，数据同步阶段应避开流量高峰期，避免造成master阻塞，影响业务正常执行</li>
<li>复制缓冲区大小设定不合理，会造成数据溢出。如进行全量复制周期太长，进行部分复制时发现数据已经存在丢失的情况，必须进行第二次全量复制，致使slave陷入死循环状态。</li>
</ol>
<pre><code>repl-backlog-size 1mb
</code></pre>
<ol start="3">
<li>master单机内存占用主机内存的比例不应过大，建议使用50%-70%的内存，留下30%-50%的内存用于执行bgsave命令和创建复制缓冲区</li>
</ol>
<p>slave：</p>
<ol>
<li>为避免slave进行全量复制、部分复制时服务器响应阻塞或数据不同步，建议关闭此期间的对外服务</li>
</ol>
<pre><code>slave-serve-stale-data yes|no
</code></pre>
<ol start="2">
<li>数据同步阶段，master发送给slave信息可以理解为master是slave的一个客户端，主动向slave发送命令</li>
<li>多个slave同时对master请求数据同步，master发送的RDB文件增多，会对带宽造成巨大冲击，如果master带宽不足，因此数据同步需要根据业务需求，适量错峰</li>
<li>slave过多时，建议调整拓扑结构，由一主多从结构变为树状结构，中间节点即是master，也是slave。注意使用树状结构时，由于层级深度，导致深度越高的slave与最顶层master间数据同步延迟较大，数据一致性变差，应谨慎选择</li>
</ol>
<h5 id="部分复制的三个核心要素">部分复制的三个核心要素</h5>
<blockquote>
<p>服务器的运行id</p>
</blockquote>
<p>概念：服务器的运行ID是每一台服务器每次运行的身份识别码，一台服务器多次运行可以生成多个运行id</p>
<p>组成：运行id由40位字符组成，是一个随机的十六进制字符</p>
<p>作用：运行id被用于在服务器间进行传输，识别身份</p>
<p>实现方式：运行id在每台服务器启动时自动生成，master在首次连接slave时，会将自己的运行id发送给slave，slave保存此id，通过info Server命令，可以查看节点的runid</p>
<blockquote>
<p>复制缓冲区</p>
</blockquote>
<p>概念：复制缓冲区，又名复制积压区，是一个先进先出的队列，用于存储服务器执行的命令，每次传播命令，master都会将传播的命令记录下来，并存储在复制缓冲区中（默认大小1M）</p>
<p>组成：偏移量、字节值</p>
<p>作用：用于保存master收到的所有指令（仅影响数据变更的指令）</p>
<p>数据来源：当master接收到主客户端的指令时，除了将指令执行，会将该指令存储到缓冲区中</p>
<blockquote>
<p>复制偏移量</p>
</blockquote>
<p>概念：一个数字，描述复制缓冲区中的指令字节位置</p>
<p>分类：</p>
<ul>
<li>master复制偏移量：记录发送给所有slave的指令字节对应的位置（多个）</li>
<li>slave复制偏移量：记录slave接收master发送过来的指令字节的位置（一个）</li>
</ul>
<p>数据来源：</p>
<ul>
<li>master：发送一次记录一次</li>
<li>slave端：接收一次记录一次</li>
</ul>
<p>作用：信息同步，对比master与slave的差异，当slave断线后，恢复数据使用</p>
<h5 id="心跳机制">心跳机制</h5>
<ul>
<li>进入命令传播阶段，master与slave之间需要进行信息交换，采用心跳机制实现双方连接保持在线</li>
<li>master心跳：
<ul>
<li>指令：PING</li>
<li>周期：由repl-ping-slave-period决定，默认为10秒</li>
<li>作用：判断slave是否在线</li>
<li>查询：INFO replication    //获取slave最后一次连接的时间间隔，lag项维持在0或1视为正常</li>
</ul>
</li>
<li>slave心跳：
<ul>
<li>指令：REPLCONF ACK {offset}</li>
<li>周期：1秒</li>
<li>作用：
<ul>
<li>向master汇报自己所复制的偏移量，判断是否一致，不一致则获取新的数据变更指令</li>
<li>判断master是否在线</li>
</ul>
</li>
</ul>
</li>
</ul>
<blockquote>
<p>心跳阶段注意事项</p>
</blockquote>
<ul>
<li>当slave多数掉线，或延迟过高时，master为保障数据稳定性，将拒绝所有信息同步操作</li>
</ul>
<pre><code>min-slaves-to-write 2
min-slaves-max-lag 10
注：slave数量小于2或是所有slave的延迟都大于10秒时，强制关闭slave的写功能，停止数据同步
</code></pre>
<ul>
<li>slave数量和延迟由slave发送<strong>REPLCONF ACK</strong>命令确认</li>
</ul>
<hr>
<h4 id="阶段3数据同步与命令传播阶段的工作流程">阶段3：数据同步与命令传播阶段的工作流程</h4>
<figure data-type="image" tabindex="4"><img src="E:%5CTypora%5CNotes%5C%E6%95%B0%E6%8D%AE%E5%BA%93%5CRedis%5CRedis%E9%9B%86%E7%BE%A4.assets%5Cimage-20200306144921188.png" alt="image-20200306144921188" loading="lazy"></figure>
<hr>
<h4 id="授权访问">授权访问</h4>
<p>master：</p>
<pre><code>配置文件中：
require &lt;password&gt;
执行时：
config set requirepass &lt;password&gt;
config get requirepass
</code></pre>
<p>slave:</p>
<pre><code>配置文件中：
masterauth &lt;password&gt;
启动时：
redis-cli -a &lt;password&gt;
执行时：
auth &lt;password&gt;
</code></pre>
<hr>
<h3 id="主从复制常见问题">主从复制常见问题</h3>
<h4 id="频繁的全量复制">频繁的全量复制</h4>
<blockquote>
<p>频繁的全量复制1</p>
</blockquote>
<ul>
<li>
<p>条件：伴随着系统运行，master的数据量会越来越大，一旦master重启，runid将发生变化，会引起slave的全量复制操作</p>
<p>内部优化调整方案：</p>
<ol>
<li>
<p>master内部创建master_replid变量，使用runid相同的策略生成，长度41位，并发送给所有slave</p>
</li>
<li>
<p>在master关闭时执行 shutdown save，进行RDB持久化，将runid与offset保存到RDB文件中</p>
<ul>
<li>
<p>repl-id	repl-offset</p>
</li>
<li>
<p>通过redis-check-rdb命令可以查看该信息</p>
</li>
</ul>
</li>
<li>
<p>master重启后加载RDB文件，恢复数据</p>
<p>重启后，将RDB文件保存到repl-id与repl-offset加载到内存中</p>
<ul>
<li>master_repl_id = repl	master_repl_offset = repl-offset</li>
<li>通过info命令可以查看该信息</li>
</ul>
</li>
</ol>
<p>作用：本机保存上次runid，重启后恢复该值，使所有slave认为还是之前的master</p>
</li>
</ul>
<blockquote>
<p>频繁的全量复制2</p>
</blockquote>
<ul>
<li>条件：网络环境不佳，出现网络中断，slave不提供服务</li>
<li>出现原因：复制缓冲区过小，断网后slave的offset越界，触发全量复制</li>
</ul>
<p>解决方案：</p>
<ul>
<li>修改复制缓冲区大侠</li>
</ul>
<pre><code>repl-backlog-size
</code></pre>
<p>建议设置如下：</p>
<ol>
<li>测算冲master到slave的重连平均时长second</li>
<li>获取maser平均每秒产生写命令数据总量write_size_per_second</li>
<li>最优复制缓冲区空间 = 2 * second * write_size_per_second</li>
</ol>
<h4 id="频繁的网络中断">频繁的网络中断</h4>
<blockquote>
<p>频繁的网络中断1</p>
</blockquote>
<ul>
<li>条件：master的CPU占用过高或slave频繁断开连接</li>
<li>出现原因：
<ul>
<li>slave每1秒发送REPLCONF ACK命令到master</li>
<li>当slave接收到了慢查询（key *，hgetall等）时，会占用大量CPU性能</li>
<li>master每1秒调用复制定时函数replicationCron()时，比对slave发现长时间未响应</li>
</ul>
</li>
</ul>
<p>解决方案：</p>
<ul>
<li>设置合理的超时时间，确认是否释放slave</li>
</ul>
<pre><code>repl-timeout	//该参数定义了超时时间的阈值（默认60秒），超过该值，释放slave
</code></pre>
<blockquote>
<p>频繁的网络中断2</p>
</blockquote>
<ul>
<li>条件：slave与master断开</li>
<li>出现原因：
<ul>
<li>master发送ping指令的频度较低</li>
<li>master设定超时时间较短</li>
<li>ping指令在网络中存在丢包</li>
</ul>
</li>
</ul>
<p>解决方案：</p>
<ul>
<li>提高ping指令的发送频度</li>
</ul>
<p>**注意：**超时时间repl-timeout的时间至少是ping指令频度的5-10倍，否则slave很容易判定超时</p>
<h4 id="数据不一致">数据不一致</h4>
<ul>
<li>条件：多个slave获取相同数据不同步</li>
<li>出现原因：网络信息不同步，数据发送有延迟</li>
</ul>
<p>解决方案：</p>
<ul>
<li>优化主从间的网络环境，通常放置在同一个机房部署，如果使用云服务器要注意此现象</li>
<li>监控主从节点延迟（通过offset）判断，如果slave延迟过大，暂时屏蔽程序对该slave的数据访问</li>
</ul>
<pre><code>slave-serve-stale-data yes|no	
//开启后仅响应info、slaveof等少数命令（慎用，除非对数据一致性要求很高）
</code></pre>
<hr>
<h2 id="哨兵模式">哨兵模式</h2>
<blockquote>
<p>简介</p>
</blockquote>
<p>哨兵（sentinel）是一个分布式系统，用于对主从结构中的每台服务器进行监控，当出现故障时通过投票机制选择新的master并将所有slave连接到新的master。</p>
<blockquote>
<p>作用</p>
</blockquote>
<ul>
<li>
<p>监控</p>
<p>不断的检查master和slave是否正常运行</p>
<p>master存活检测、master与slave运行情况检测</p>
</li>
<li>
<p>通知（提醒）</p>
<p>当被监控的服务器出现问题时，向其他（哨兵间、客户端）发送通知</p>
</li>
<li>
<p>自动故障转移</p>
<p>断开master与slave连接，选取一个slave作为master，将其他slave连接到新的master，并告知客户端新的master的地址</p>
</li>
</ul>
<p>**注意：**哨兵也是一台redis服务器，只是不提供数据服务，并且通常哨兵配置数量为单数</p>
<h3 id="配置哨兵">配置哨兵</h3>
<p>通过配置文件配置，配置后使用命令启动</p>
<ul>
<li>配置文件</li>
</ul>
<pre><code class="language-linux">[root@localhost redis-4.0.6]# cat sentinel.conf | grep -v &quot;#&quot; | grep -v &quot;^$&quot;
port 26379
dir /tmp
sentinel monitor mymaster 127.0.0.1 6379 2
sentinel down-after-milliseconds mymaster 30000
sentinel parallel-syncs mymaster 1
sentinel failover-timeout mymaster 180000
----------------------------------------------------------------------------
以上分别为：
端口号
路径
监控的master 地址 端口号 哨兵认定数量
连接未响应时长
重设master后同时同步数量
认定下线时间（毫秒）
</code></pre>
<ul>
<li>启动命令</li>
</ul>
<pre><code class="language-redis">redis-sentinel sentinel-端口号.conf
</code></pre>
<ul>
<li>连接命令</li>
</ul>
<pre><code>redis-cli -p 端口号
</code></pre>
<p>**注意：**在服务启动后哨兵的配置文件会发生改变</p>
<h3 id="工作原理">工作原理</h3>
<blockquote>
<p>阶段一：监控阶段</p>
</blockquote>
<ul>
<li>
<p>用于同步各个节点的状态信息</p>
<ul>
<li>获取各个sentinel的状态（是否在线）</li>
<li>获取master的状态
<ul>
<li>master属性
<ul>
<li>runid</li>
<li>role：master</li>
</ul>
</li>
<li>各个slave的详细信息</li>
</ul>
</li>
<li>获取所有slave的状态（根据master中的slave信息）
<ul>
<li>slave属性
<ul>
<li>runid</li>
<li>role：slave</li>
<li>master_host、master_port</li>
<li>offset</li>
<li>......</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p>工作内容：</p>
<ol>
<li>第一个sentinel与master进行连接后，发送info指令</li>
<li>建立长期cmd连接，sentinal同时保存所有哨兵状态，master中记录redis实例信息</li>
<li>通过master中的slave信息与其中的slave进行连接并发送info指令</li>
<li>第二个sentinel进入，与master连接发送info指令，发现master端的sentinels中有信息</li>
<li>与第一个sentinel建立连接并同步信息，互相发送ping命令保证对方在线，并于master建立cmd连接</li>
</ol>
</li>
</ul>
<figure data-type="image" tabindex="5"><img src="E:%5CTypora%5CNotes%5C%E6%95%B0%E6%8D%AE%E5%BA%93%5CRedis%5CRedis%E9%9B%86%E7%BE%A4.assets%5Cimage-20200306182151521.png" alt="" loading="lazy"></figure>
<blockquote>
<p>通知阶段</p>
</blockquote>
<ul>
<li>工作内容：由其中一个sentinel通过建立的cmd连接获取主从机的工作状态，获取到信息并且与相互连接的其他sentinel之间进行信息同步。</li>
</ul>
<figure data-type="image" tabindex="6"><img src="E:%5CTypora%5CNotes%5C%E6%95%B0%E6%8D%AE%E5%BA%93%5CRedis%5CRedis%E9%9B%86%E7%BE%A4.assets%5Cimage-20200306181804282.png" alt="image-20200306181804282" loading="lazy"></figure>
<blockquote>
<p>故障转移阶段</p>
</blockquote>
<ul>
<li>故障转移阶段引起原因：</li>
</ul>
<ol>
<li>其中一台sentinel多次获取master状态失败</li>
<li>将master中标记为SRI_S_DOWN（主观下线）</li>
<li>在sentinel之间传播，表示发现master掉线</li>
<li>其他sentinel连接master</li>
<li>连接失败的sentinel在sentinel之间表示发现master掉线</li>
<li>连接失败的sentinel占sentinel总数超过一半时，将master标记为SRI_O_DOWN（客观下线），确定master掉线</li>
</ol>
<figure data-type="image" tabindex="7"><img src="E:%5CTypora%5CNotes%5C%E6%95%B0%E6%8D%AE%E5%BA%93%5CRedis%5CRedis%E9%9B%86%E7%BE%A4.assets%5Cimage-20200306184201644.png" alt="image-20200306184201644" loading="lazy"></figure>
<ul>
<li>选出sentinel担任处置工作：</li>
</ul>
<ol>
<li>所有的sentinel同时对其余的sentinel发送一条指令（SENTINEL is-master-down-by...），其中包含：下线的ip、下线的端口、竞选次数、runid</li>
<li>通过循环的投票机制，选出一台sentinel担任处置工作
<ul>
<li>投票机制：每个sentinel均是投票者也是参选者，例如：当前有五台sentinel，其中4台sentinel会同时向剩余的一台sentinel发送自己的信息，剩余这台的sentinel会将自己的票投给信息最先到达的sentinel，最后通过所有投票情况选出获得票数最多的sentinel。</li>
</ul>
</li>
</ol>
<figure data-type="image" tabindex="8"><img src="E:%5CTypora%5CNotes%5C%E6%95%B0%E6%8D%AE%E5%BA%93%5CRedis%5CRedis%E9%9B%86%E7%BE%A4.assets%5Cimage-20200306202853958.png" alt="image-20200306202853958" loading="lazy"></figure>
<ul>
<li>
<p>通过投票机制产生的sentinel从服务器列表中选择出备选的master</p>
<ul>
<li>担任master的选择方式：
<ol>
<li>在线的</li>
<li>响应速度快的</li>
<li>与原master断开时间短的</li>
<li>优先原则：
<ol>
<li>优先级</li>
<li>offset</li>
<li>runid</li>
</ol>
</li>
</ol>
</li>
</ul>
</li>
<li>
<p>发送指令</p>
<ol>
<li>向新的master发送slaveof no one，表示与master断开连接</li>
<li>向其他slave发送slaveof 新master的IP 端口，使其他slave与新master产生主从关系</li>
</ol>
</li>
</ul>
<hr>
<h2 id="集群">集群</h2>
<h3 id="集群简介">集群简介</h3>
<blockquote>
<p>集群架构</p>
</blockquote>
<ul>
<li>集群就是使用网络将若干台计算机连接到一起，并且提供同一的管理方式，使其对外呈现单机的服务效果</li>
</ul>
<blockquote>
<p>集群作用</p>
</blockquote>
<ul>
<li>分散单台服务器的访问压力，实现负载均衡</li>
<li>分散单台服务器的存储压力，实现可扩展性</li>
<li>降低单台服务器宕机带来的灾难性的影响</li>
</ul>
<h3 id="redis集群结构设计">Redis集群结构设计</h3>
<blockquote>
<p>数据存储设计</p>
</blockquote>
<ul>
<li>Redis会将所有的服务器的存储空间等分切割为16384份，切割后的每一个空间称之为一个槽</li>
<li>当需要存储数据时，首先将该数据通过RCR16（循环冗余校验）生成的值与16384取模，得到结果</li>
<li>按照key计算得到的结果，存储至对应的槽中</li>
<li>当有新的服务器加入或是有服务器退出时，已存在服务器将自己的槽位分享给新机器或是退出服务器将其所持有的槽位分享给剩余机器</li>
</ul>
<blockquote>
<p>集群内部通讯设计</p>
</blockquote>
<ul>
<li>
<p>当搭建好集群后，所有服务器将会建立连接互相通信，记录各个库中槽的编号数据</p>
</li>
<li>
<p>当有数据进入，如果第一次访问到的计算机直接命中，则返回数据</p>
</li>
<li>
<p>如果所需存储数据不在第一次访问的计算机中，则返回所在计算机位置，通过该位置访问获取数据</p>
<p>结论：最多两次可以命中数据</p>
</li>
</ul>
<h3 id="集群搭建">集群搭建</h3>
<ul>
<li>配置文件</li>
</ul>
<pre><code>cluster-enabled yes|no				//启动cluster集群，称为集群中的一个节点
cluster-config-file &lt;filename&gt;		//启动配置文件位置
cluster-node-time &lt;milliseconds&gt;	//超时时间，单位为毫秒数
cluster-migartion-barrier &lt;count&gt;	//master连接slave的最小数量
</code></pre>
<ul>
<li>启动集群方式</li>
</ul>
<pre><code class="language-linux">redis-trib.rb create --replicas 数字 master的ip:port ... slave的ip:port ...
//replicas用于指定内部结构，数字表示一个master对应几个slave
</code></pre>
<ul>
<li>连接至集群方式</li>
</ul>
<pre><code class="language-linux">redis-cli -c 		//以集群方式启动客户端
</code></pre>
<ul>
<li>主从下线与主从切换
<ul>
<li>当从机下线后，对应的主机发送信息标记从机下线</li>
<li>主机下线后，从机多次连接失败，进行故障转移，产生新的master，并标记原有master状态为fail，当原先master上线，自动转换为slave</li>
</ul>
</li>
</ul>
<blockquote>
<p>cluster节点操作命令</p>
</blockquote>
<pre><code class="language-linux">cluster nodes					//查看集群节点信息
cluster replicate &lt;master-id&gt;	//切换主节点
cluster meet ip:port			//新增主节点
cluster forget &lt;id&gt;				//忽略一个没有solt的节点
cluster failover				//手动故障转移
</code></pre>
<hr>
<h2 id="企业级解决方案">企业级解决方案</h2>
<h3 id="缓存预热">缓存预热</h3>
<blockquote>
<p>现象</p>
</blockquote>
<p>服务器启动后迅速宕机</p>
<blockquote>
<p>问题排查</p>
</blockquote>
<ol>
<li>请求数量较高</li>
<li>主从之间数据吞吐量较大，数据同步操作频度较高</li>
</ol>
<blockquote>
<p>解决方案</p>
</blockquote>
<p>前置准备工作：</p>
<ol>
<li>日常例行统计数据访问记录，统计访问频度较高的热点数据</li>
<li>如果热点数据量较大，利用LRU数据删除策略，构建数据留存队列（手工维护或storm+kafka等）</li>
</ol>
<p>启动前准备工作：</p>
<ol>
<li>将统计结果中的数据分类，根据级别，redis优先加载级别较高的热点数据</li>
<li>利用分布式多服务器同时进行数据读取，提速数据加载过程</li>
</ol>
<p>实施：</p>
<ol>
<li>使用脚本程序固定触发数据预热过程</li>
<li>如果条件允许，使用CDN（内容分发网络）</li>
</ol>
<blockquote>
<p>总结</p>
</blockquote>
<p>缓存预热就是系统启动前，提前将相关的缓存数据直接加载到缓存系统，从而避免在用户请求的时候，先查询数据库，然后再将数据缓存到redis的问题。用户直接查询事先被预热的数据。</p>
<h3 id="缓存雪崩">缓存雪崩</h3>
<blockquote>
<p>现象</p>
</blockquote>
<ol>
<li>系统平稳运行过程中，忽然数据库连接量激增</li>
<li>应用服务器无法及时处理请求</li>
<li>用户访问时返回408、500等错误页面</li>
<li>客户反复刷新页面，请求量继续增大</li>
<li>数据库崩溃</li>
<li>应用服务器崩溃</li>
<li>重启服务器后无效</li>
<li>Redis服务器崩溃</li>
<li>Redis集群崩溃</li>
<li>重启库数据后再次被瞬间浏览击倒</li>
</ol>
<blockquote>
<p>问题排查</p>
</blockquote>
<ol>
<li>在一个<strong>较短</strong>的时间内，缓存中<strong>较多</strong>的key<strong>集中过期</strong></li>
<li>此周期内请求访问过期的数据，redis未命中，便向数据库获取数据</li>
<li>数据库同时接收到大量的请求无法及时处理</li>
<li>Redis大量请求被积压，开始出现超时现象</li>
<li>数据库流量激增，导致数据库崩溃</li>
<li>重启数据库后Redis缓存中仍然无数据可用</li>
<li>Redis服务器资源被严重占用，服务器崩溃</li>
<li>Redis集群崩溃瓦解</li>
<li>应用服务器无法及时得到数据响应请求，来自客户端的请求数量越来越多，应用服务器崩溃</li>
<li>应用服务器、redis、数据库全部重启，效果不理想</li>
</ol>
<blockquote>
<p>解决方案</p>
</blockquote>
<p>道（针对问题如何设计）：</p>
<ol>
<li>
<p>对页面内容进行更多的静态化处理</p>
</li>
<li>
<p>构建多级缓存架构，如：Nginx缓存+Redis缓存+ehcache缓存</p>
</li>
<li>
<p>检测Mysql严重耗时业务进行优化（对数据库的拼劲排查：例如超时查询、耗时较高事务等）</p>
</li>
<li>
<p>灾难预警机制</p>
<p>监控Redis服务器性能指标</p>
<ul>
<li>CPU占用率、CPU使用率</li>
<li>内存容量</li>
<li>查询平均响应时间</li>
<li>线程数</li>
</ul>
</li>
<li>
<p>限流、降级</p>
<p>短时间范围内牺牲一些用户体验，限制一部分请求访问，降低应用服务器压力，待业务低俗运转后再逐步开放访问</p>
</li>
</ol>
<p>术（针对问题如何解决）：</p>
<ol>
<li>
<p>LRU与LFU切换</p>
</li>
<li>
<p>数据有效期策略调整</p>
<ul>
<li>根据业务有效期进行分类错峰（不同品类不同过期时间）</li>
<li>过期时间使用固定时间+随机值的形式，稀释集中到期的key的数量</li>
</ul>
</li>
<li>
<p>超热数据使用永久key</p>
</li>
<li>
<p>定期维护（自动+人工）</p>
<p>对即将过期数据做访问量分析，确认是否延时，配合访问量统计，做热点数据延时</p>
</li>
<li>
<p>加锁（慎用）</p>
</li>
</ol>
<blockquote>
<p>总结</p>
</blockquote>
<p>缓存雪崩就是瞬间过期数据量太大，导致对数据库服务器造成压力。如能够有效避免过期时间集中，可以有效解决雪崩现象的出现（约40%），配合其他策略一起使用，并监控服务器的运行数据，根据运行记录做快速调整。</p>
<h3 id="缓存击穿">缓存击穿</h3>
<blockquote>
<p>现象</p>
</blockquote>
<ol>
<li>系统平稳运行</li>
<li>数据库连接量瞬间激增</li>
<li>Redis服务器无大量key过期</li>
<li>Redis内存平稳，无波动</li>
<li>Redis服务器CPU正常</li>
<li>数据库出现崩溃</li>
</ol>
<blockquote>
<p>问题排查</p>
</blockquote>
<ol>
<li>Redis中某个key过期，该key的访问量巨大</li>
<li>多个对于该数据的请求从服务器直接压到Redis中，均未名中</li>
<li>Redis在短时间内发起了大量对数据库中同一数据的访问</li>
</ol>
<blockquote>
<p>解决方案</p>
</blockquote>
<p>术：</p>
<ol>
<li>预先设计：对于热点数据的key预先设定更长的过期时常</li>
<li>现场调整：监控访问量，对自然流量激增的数据延长过期时间或设置永久性key</li>
<li>后台刷新数据：启动定时任务，高峰期来临之前，刷新数据有效期，确保不丢失</li>
<li>二级缓存：设置不同的失效时间，保障不会被同时淘汰</li>
<li>加锁：分布式锁，防止被击穿，但也要注意性能瓶颈（慎重）</li>
</ol>
<blockquote>
<p>总结</p>
</blockquote>
<p>缓存击穿就是单个高热数据过期的瞬间，数据访问量较大，未名中redis后，发起了大量对统一数据的数据库访问，导致对数据库服务器造成压力。应对策略应该在业务数据分析与预防方面进行，配合运行监控与即时调整策略，毕竟单个key的过期监控难度较高，配合雪崩处理策略即可。</p>
<h3 id="缓存穿透">缓存穿透</h3>
<blockquote>
<p>现象</p>
</blockquote>
<ol>
<li>系统平稳运行过程中</li>
<li>应用服务器流量随时间增量较大</li>
<li>Redis服务器命中率随时间逐步降低</li>
<li>Redis内存平稳无压力</li>
<li>Redis服务器CPU占用激增</li>
<li>数据库服务器压力激增</li>
<li>数据库崩溃</li>
</ol>
<blockquote>
<p>问题排查</p>
</blockquote>
<ul>
<li>获取的数据在数据库中也不存在，数据库查询未得到对应数据</li>
<li>Redis获取到null数据未进行持久化，直接返回</li>
<li>重复出现访问不存在的数据</li>
<li>出现黑客攻击服务器</li>
</ul>
<blockquote>
<p>解决方案</p>
</blockquote>
<p>术：</p>
<ol>
<li>
<p>缓存null：对于查询结果为null的数据进行缓存（长期使用，定时清理），设定短时限（30-60s，最多5分钟）</p>
</li>
<li>
<p>白名单策略</p>
<ul>
<li>提前预热各种分类数据id对应bitmaps，id作为bitmaps的offset，相当于设置数据白名单。当正常加载时放行，加载异常数据时直接拦截（效率偏低）</li>
<li>使用布隆过滤器</li>
</ul>
</li>
<li>
<p>实时监控：实时监控redis命中率（业务正常范围时，通常会有一个波动值）与null数据的占比</p>
<ul>
<li>非活动时段波动：通常检测3-5倍，超过5倍纳入重点排查对象</li>
<li>活动时段波动：通常检测10-50倍，超过50倍纳入重点排查对象</li>
</ul>
</li>
<li>
<p>key加密</p>
<p>问题出现后，临时启动防灾业务key，对key进行业务层传输加密服务，设定校验程序，对key进行校验，不满足校验则驳回数据访问</p>
</li>
</ol>
<blockquote>
<p>总结</p>
</blockquote>
<p>缓存穿透访问了不存在的数据，跳过了合法数据的redis数据缓存阶段，每次都对数据库进行访问，导致对数据库服务器造成压力。通常此类数据的出现量是一个较低的值，当出现此类情况以毒攻毒，并及时<strong>报警</strong>。应对策略应在临时预案防范多做文章。</p>
<p>无论是黑名单还是白名单，都是对整体系统的压力，警报解除后需要尽快移除。</p>
<h3 id="性能指标监控">性能指标监控</h3>
<blockquote>
<p>监控指标</p>
</blockquote>
<ul>
<li>性能指标：Performance（响应时间、每秒处理请求数、缓存命中率）</li>
<li>内存指标：Memory（已使用内存、内存碎片率、由于最大内存策略被移除key的数量、阻塞操作导致阻塞的量）</li>
<li>基本活动指标：Basic activity（客户端连接数、Slave数量、最近一次主从交互后的秒数、数据库中key值的总数）</li>
<li>持久性指标：Persistence（最后一次持久化到磁盘的时间戳、最后一次持久化后的数据库更改数）</li>
<li>错误指标：Error（达到最大连接数后拒绝的连接数、key的未命中次数、主从断开的时间）</li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Redis高级]]></title>
        <id>https://Squid-dot.github.io/post/redis-gao-ji/</id>
        <link href="https://Squid-dot.github.io/post/redis-gao-ji/">
        </link>
        <updated>2020-03-06T13:17:56.000Z</updated>
        <content type="html"><![CDATA[<h1 id="redis高级">Redis高级</h1>
<h2 id="linux环境下的redis">Linux环境下的Redis</h2>
<h3 id="在linux环境中安装redis">在Linux环境中安装redis</h3>
<blockquote>
<p>下载安装包</p>
</blockquote>
<pre><code># wget http://download.redis.io/releases/redis-?.?.?.tar.gz
</code></pre>
<blockquote>
<p>解压</p>
</blockquote>
<pre><code>tar -xvf 文件名.tar.gz
</code></pre>
<blockquote>
<p>编译</p>
</blockquote>
<pre><code>make
</code></pre>
<blockquote>
<p>安装</p>
</blockquote>
<pre><code>make install
</code></pre>
<hr>
<h3 id="启动redis服务">启动Redis服务</h3>
<blockquote>
<p>直接启动</p>
</blockquote>
<ul>
<li>进入redis下的src目录，打开redis-server</li>
</ul>
<pre><code># redis-server [port]
</code></pre>
<ul>
<li>打开redis-cli</li>
</ul>
<pre><code># redis-cli [-h host] [-p port]
</code></pre>
<blockquote>
<p>指定配置文件启动*</p>
</blockquote>
<ul>
<li>
<p>编写指定配置文件 xxx.conf</p>
</li>
<li>
<p>打开服务时指定</p>
</li>
</ul>
<pre><code># redis-server [配置文件]
</code></pre>
<hr>
<h2 id="持久化">持久化</h2>
<blockquote>
<p>什么是持久化</p>
</blockquote>
<p>利用永久性存储介质将数据进行保存，在特定的时间将保存的数据进行恢复的工作机制称为永久化。</p>
<blockquote>
<p>持久化的方式</p>
</blockquote>
<ul>
<li>将当前数据状态进行保存，快照形式，存储数据结果，存储格式简单，关注点在数据（RDB）</li>
<li>将数据的操作过程进行保存，日志形式，存储操作过程，存储格式复杂，关注点在数据的操作过程（AOF）</li>
</ul>
<h3 id="rdb方式">RDB方式</h3>
<blockquote>
<p>命令</p>
</blockquote>
<pre><code>save	//作用：手动执行一次保存操作
bgsave	//作用：手动启动后台保存操作，但不是立即执行
save second changes		//作用：在一定时间内key的数量变化达到指定值时自动执行持久							化，后台是bgsave
特殊形式：
debug reload	//服务器运行过程中保存
shutdown save	//关闭服务器时指定保存数据
</code></pre>
<p>**注意：**save指令的执行会阻塞当前Redis服务器，直到当前RDB过程完成为止，有可能会长时间阻塞，线上环境不建议使用；而bgsave是针对save阻塞问题做的优化，通过调用linux中的fork函数生成子进程保存，Redis中所有涉及到RDB操作都采用bgsave的方式，save命令可以放弃使用。</p>
<blockquote>
<p>save指令的相关配置</p>
</blockquote>
<ul>
<li>
<p>dbfilename dump.rdb</p>
<p>说明：设置本地数据库文件名，默认值为dump.rdb</p>
<p>经验：通常设置为dump-端口号.rdb</p>
</li>
<li>
<p>dir</p>
<p>说明：设置存储.rdb文件的路径</p>
<p>经验：通常设置成存储空间较大的目录中，目录名称data</p>
</li>
<li>
<p>rdbcompression yes</p>
<p>说明：设置存储至本地数据库时是否压缩数据，默认为yes，采用LZF压缩</p>
<p>经验：通常默认为开启状态，如果设置为no，可以节省CPU运行时间，但会使存储的文件变大（巨大）</p>
</li>
<li>
<p>rdbchecksum yes</p>
<p>说明：设置是否进行RDB文件格式校验，该校验过程在写文件和读文件过程均进行</p>
<p>经验：通常默认为开启状态，如果设置为no，可以节约读写性能过程约10%时间消耗，但是存在一定的数据损坏风险</p>
</li>
<li>
<p>stop-writes-on-bgsave-error yes</p>
<p>说明：后台存储过程中如果出现错误现象，是否停止保存操作（bgsave的配置）</p>
<p>经验：通常默认为开启状态</p>
</li>
</ul>
<blockquote>
<p>对比</p>
</blockquote>
<table>
<thead>
<tr>
<th style="text-align:center">方式</th>
<th style="text-align:center">save指令</th>
<th style="text-align:center">bgsave指令</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">读写</td>
<td style="text-align:center">同步</td>
<td style="text-align:center">异步</td>
</tr>
<tr>
<td style="text-align:center">阻塞客户端指令</td>
<td style="text-align:center">是</td>
<td style="text-align:center">否</td>
</tr>
<tr>
<td style="text-align:center">额外内存消耗</td>
<td style="text-align:center">否</td>
<td style="text-align:center">是</td>
</tr>
<tr>
<td style="text-align:center">启动新进程</td>
<td style="text-align:center">否</td>
<td style="text-align:center">是</td>
</tr>
</tbody>
</table>
<blockquote>
<p>RDB的优缺点</p>
</blockquote>
<p>优点：</p>
<ul>
<li>RDB时一个紧凑压缩的二进制文件，存储效率较高</li>
<li>RDB内部存储的时redis在某个时间点的数据快照，非常适合用于数据备份，全量复制等场景</li>
<li>RDB恢复数据的速度要比AOF快很多</li>
<li>应用：服务器中没X消失执行bgsave备份，并将RDB文件拷贝到远程机器中，用于灾难恢复</li>
</ul>
<p>缺点：</p>
<ul>
<li>RDB方式无论是执行指令还是利用配置，无法做到实时持久化，具有较大可能性丢失数据</li>
<li>bgsave指令每次运行要执行fork操作创建子进程，要牺牲掉一些性能</li>
<li>Redis的众多版本中未进行RDB文件格式的版本同一，有可能出现各版本之间数据格式无法兼容现象</li>
</ul>
<hr>
<h3 id="aof方式">AOF方式</h3>
<blockquote>
<p>概念</p>
</blockquote>
<ul>
<li>AOF(append only file)持久化：以独立日志的方式记录每次写命令，重启时重新执行AOF文件中的命令已达到恢复数据的目的。与RDB相比可以简单描述为将记录数据转变为记录数据产生的过程。</li>
<li>AOF的主要作用是解决了数据持久化的实时性，目前已经是Redis持久化的主流方案。</li>
</ul>
<blockquote>
<p>AOF写数据的三种策略</p>
</blockquote>
<ul>
<li>
<p>always（每次）</p>
<p>每次写入操作均同步到AOF文件中，数据零误差，性能较低</p>
</li>
<li>
<p>everysec（每秒）</p>
<p>每秒将缓冲区中的指令同步到AOF文件中，数据准确性较高，性能较高</p>
<p>在系统突然宕机的情况下丢失1秒内的数据</p>
</li>
<li>
<p>no（系统控制）</p>
<p>由操作系统控制每次同步到AOF文件的周期，整体过程不可控</p>
</li>
</ul>
<blockquote>
<p>AOF功能开启</p>
</blockquote>
<ul>
<li>配置</li>
</ul>
<pre><code class="language-linux">appendonly yes|no		//是否开启AOF持久化功能，默认为不开启状态
appendfsync always|everysec|no		//AOF写数据策略
appendfilename filename		//AOF持久化文件名，默认文件名为appendonly.aof,建议								  配置为appendonly-端口号.aof
</code></pre>
<hr>
<h4 id="aof重写">AOF重写</h4>
<blockquote>
<p>作用</p>
</blockquote>
<ul>
<li>降低磁盘占用量，提高磁盘利用率</li>
<li>提高持久化效率，降低持久化写时间，提高IO性能</li>
<li>降低数据恢复用时，提高数据恢复效率</li>
</ul>
<blockquote>
<p>AOF重写方式</p>
</blockquote>
<ul>
<li>手动重写</li>
</ul>
<pre><code class="language-linux">bgrewriteaof
</code></pre>
<ul>
<li>自动重写</li>
</ul>
<pre><code>auto-aof-rewrite-min-size size
auto-aof-rewrite-percentage percentage
</code></pre>
<hr>
<h3 id="rdb与aof对比">RDB与AOF对比</h3>
<table>
<thead>
<tr>
<th style="text-align:center">持久化方式</th>
<th style="text-align:center">RDB</th>
<th style="text-align:center">AOF</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">占用存储空间</td>
<td style="text-align:center">小（数据级：压缩）</td>
<td style="text-align:center">大（指令级：重写）</td>
</tr>
<tr>
<td style="text-align:center">存储速度</td>
<td style="text-align:center">慢</td>
<td style="text-align:center">快</td>
</tr>
<tr>
<td style="text-align:center">恢复速度</td>
<td style="text-align:center">快</td>
<td style="text-align:center">慢</td>
</tr>
<tr>
<td style="text-align:center">数据安全性</td>
<td style="text-align:center">会丢失数据</td>
<td style="text-align:center">依据策略决定</td>
</tr>
<tr>
<td style="text-align:center">资源消耗</td>
<td style="text-align:center">高/重量级</td>
<td style="text-align:center">低/轻量级</td>
</tr>
<tr>
<td style="text-align:center">启动优先级</td>
<td style="text-align:center">低</td>
<td style="text-align:center">高</td>
</tr>
</tbody>
</table>
<hr>
<h2 id="事务">事务</h2>
<blockquote>
<p>简介</p>
</blockquote>
<p>Redis事务就是一个命令执行的队列，将一系列预定义命令包装成一个整体（一个队列）。当执行时，一次性按照添加顺序依次执行，中间不会被打断或者干扰。</p>
<p>总结：一个队列中，一次性、顺序性、排他性的执行一系列命令。</p>
<blockquote>
<p>事务的基本操作</p>
</blockquote>
<pre><code>multi		//设置事务的开启位置，此指令执行后，后续的所有指令均加入到事务中
exec		//设置事务的结束位置，同时执行事务。与multi成对出现，成对使用
discard		//终止当前事务的定义，发生在multi之后，exec之前
</code></pre>
<p>**注意：**已经执行完毕的命令对应的数据不会自动回滚，需要程序员在代码中实现回滚。</p>
<blockquote>
<p>锁</p>
</blockquote>
<p>事务锁：</p>
<pre><code>watch key1 [key2...]	//对key添加监视锁，在执行exec前如果key发生了变化，终止事							务执行
unwatch					//取消对所有key的监视
</code></pre>
<p>分布式锁：</p>
<pre><code>setnx lock-key value	//使用setnx设置一个公共锁
del lock-key			//删除一个公共锁
添加时间设定的锁：
expire lock-key second
pexpire lock-key milliseconds
</code></pre>
<p>​		利用setnx命令的返回值特征，有值返回则设置失败，无值返回则设置成功：</p>
<p>​				1.对于返回设置成功的，拥有控制权，进行下一步的具体业务操作</p>
<p>​				2.对于返回设置失败的，不具有控制权，排队或等待</p>
<hr>
<h2 id="删除策略">删除策略</h2>
<h3 id="数据删除策略">数据删除策略</h3>
<blockquote>
<p>Redis中数据的特征</p>
</blockquote>
<p>Redis是一种内存级数据库，所有数据均存放在内存中，内存中的数据可以通过TTL指令获取其状态</p>
<ul>
<li>XX：具有时效性的数据</li>
<li>-1：永久有效的数据</li>
<li>-2：已经过期的数据或被删除的数据、未定义的数据</li>
</ul>
<blockquote>
<p>Redis中时效性数据的存储结构</p>
</blockquote>
<figure data-type="image" tabindex="1"><img src="E:%5CTypora%5CNotes%5C%E6%95%B0%E6%8D%AE%E5%BA%93%5CRedis%5CRedis%E9%AB%98%E7%BA%A7.assets%5Cimage-20200303190313869.png" alt="image-20200303190338409" loading="lazy"></figure>
<blockquote>
<p>目标</p>
</blockquote>
<p>在内存占用与CPU占用之间寻找一种平衡，顾此失彼都会造成整体redis性能的下降，甚至引发服务器宕机或内存泄漏</p>
<hr>
<h4 id="定时删除">定时删除</h4>
<ul>
<li>创建一个定时器，当key设置有过期时间，且过期时间到达时，由定时器任务立即执行对键的删除操作。</li>
<li>优点：节约内存，到时就删除，快速释放掉不必要的内存占用</li>
<li>缺点：CPU压力很大，无论CPU此时负载多高，均占用CPU，会影响Redis服务器响应时间和指令吞吐量</li>
<li>总结：用处理器性能换取存储空间</li>
</ul>
<hr>
<h4 id="惰性删除">惰性删除</h4>
<ul>
<li>数据到达过期时间，不做处理，等下次访问该数据时删除</li>
<li>优点：节约CPU性能，发现必须删除的时候才删除</li>
<li>缺点：内存压力很大，出现长期占用内存的数据</li>
<li>总结：用存储空间换取处理器性能</li>
</ul>
<hr>
<h4 id="定期删除">定期删除</h4>
<pre><code>* Redis启动服务器初始化时，读取配置server.hz的值，默认为10
* 每秒钟执行server.hz次 serverCron() -&gt; databaseCron() -&gt; activeExpireCycle()
* activeExpireCycle()对每个expire[*]（每个数据库对应一个expire）逐一进行检测，每	次执行250ms/server.hz
* 对某个expires[*]检测时，随机挑选W个key检测
      * 如果key超时，删除key
      * 如果一轮中删除的kshaney的数量&gt;W*25%，循环该过程
      * 如果一轮中删除的kshaney的数量≤W*25%，检查下一个expire[\*]，0-15循环
      * W取值=ACTIVE_EXPIRE_CYCLE_LOOKUPS_PER_LOOP属性值
* 参数current_db用于记录activeExpireCycle()进入哪个expire[*]执行
</code></pre>
<ul>
<li>周期性轮询redis库中的时效性数据，采用随机抽取的策略，利用过期数据占比的方式控制删除频度</li>
<li>特点1：CPU性能占用设置有峰值，检测频度可以自定义设置</li>
<li>特点2：内存压力不是很大，长期占用内存的冷数据会被持续清理</li>
<li>总结：周期性抽查存储空间</li>
</ul>
<p><strong>在Redis中，同时使用 惰性删除 与 定期删除 两种策略。</strong></p>
<hr>
<h3 id="数据逐出策略">数据逐出策略</h3>
<blockquote>
<p>什么是逐出算法</p>
</blockquote>
<p>Redis使用内存存储数据，在执行每一个命令前，会调用freeMemoryIfNeeded()检测内存是否充足。如果内存不满足新加入数据的最低存储要求，redis会临时删除一些数据为当前指令清理内存空间。清理数据的策略称为逐出算法。</p>
<p>**注意：**逐出数据的过程不是100%能够清理出足够的可使用的内存空间，如果不成功则反复执行。当对所有数据尝试完毕后，如果不能达到内存清理的要求，将出现错误信息。</p>
<blockquote>
<p>影像数据逐出的相关配置</p>
</blockquote>
<pre><code>maxmemory			//最大可使用内存，为物理占用内存的比例，默认0，生产环境中一般					设置50%以上
maxmemory-samples	//每次选取待删除数据的个数
maxmemory-policy	//达到最大内存后的逐出策略
</code></pre>
<p>可选的逐出策略：</p>
<ul>
<li>检测易失数据（可能会过期的数据集server.db[i].expires）</li>
</ul>
<ol>
<li>volatile-lru：挑选最近使用时间最少的数据</li>
<li>volatile-lfu：挑选最近使用次数最少的数据</li>
<li>volatile-ttl：挑选将要过期的数据</li>
<li>volatile-random：任意选择数据</li>
</ol>
<ul>
<li>检测全库数据（所有数据集server.db[i].dict）</li>
</ul>
<ol>
<li>allkeys-lru：挑选最近使用时间最少的数据</li>
<li>allkeys-lfu：挑选最近使用次数最少的数据</li>
<li>allkeys-random：任意选择数据</li>
</ol>
<ul>
<li>放弃数据驱逐</li>
</ul>
<ol>
<li>no-enviction：禁止驱逐，会引发OOM</li>
</ol>
<hr>
<h2 id="服务器配置">服务器配置</h2>
<blockquote>
<p>基础配置</p>
</blockquote>
<pre><code>daemonize yes|no			//设置服务器以守护进程的方式运行
bind 127.0.0.1				//绑定主机地址
port 6379					//设置服务器端口号
databases 16				//设置数据库数量

</code></pre>
<blockquote>
<p>日志配置</p>
</blockquote>
<pre><code>loglevel debug|verbose|notice|warning		//设置服务器的日志级别
logfile	端口号.log							 //日志记录文件名

</code></pre>
<blockquote>
<p>客户端配置</p>
</blockquote>
<pre><code>maxclients 0				//设置同一时间最大客户端连接数
timeout						//客户端闲置等待最大时常，达到最大值后关闭连接，关闭								设置为0

</code></pre>
<blockquote>
<p>多服务器快捷配置</p>
</blockquote>
<pre><code>include /path/server-端口号.conf	//导入并加载指定配置文件信息

</code></pre>
<hr>
<h2 id="高级数据类型">高级数据类型</h2>
<h3 id="bitmaps">Bitmaps</h3>
<blockquote>
<p>简介</p>
</blockquote>
<p>Redis提供了Bitmaps这个“数据结构”可以实现对位的操作。 把数据结构加上引号主要因为：</p>
<ul>
<li>Bitmaps本身不是一种数据结构，实际上它就是字符串，但是它可以对字符串的位进行操作。</li>
<li>Bitmaps单独提供了一套命令，所以在Redis中使用Bitmaps和使用字符串的方法不太相同。 可以把Bitmaps想象成一个以位为单位的数组，数组的每个单元只能存储0和1，数组的下标在Bitmaps中叫做偏移量。</li>
</ul>
<p>总结：设置对应的bit串，每一位的0/1值作为判定条件。如1010001，每一位对应一个用户是否访问。</p>
<blockquote>
<p>操作</p>
</blockquote>
<pre><code>getbit key offset				//获取指定key对应偏移量上的bit值
setbit key offset value			//设置指定key对应偏移量上的bit值，取0或1
bitcount key [start end]		//计算指定key中1的数量
bitop op destkey key1 [key2...]	//对指定key进行位运算并将结果保存在destkey中
	op的取值：and|or|not|xor

</code></pre>
<hr>
<h3 id="hyperloglog">HyperLogLog</h3>
<blockquote>
<p>简介</p>
</blockquote>
<p>HyperLogLog是用于统计基数的。</p>
<p>基数：集合去重后的元素个数。如：{1,3,5,7,5,7,8}的基数为{1,3,5,7,8}</p>
<blockquote>
<p>操作</p>
</blockquote>
<pre><code>pfadd key element [element...]				//添加数据
pfcount key [key...]						//统计数据
pfmerge destkey sourcekey [sourcekey...]	//合并数据

</code></pre>
<p><strong>注意：</strong></p>
<ul>
<li>用于进行基数统计，不是集合，不是保存数据，只记录数量而不是记录数据</li>
<li>核心是基数估算算法，最终数值存在一定误差</li>
<li>误差范围：基数估计是结果是一个带有0.81%标准错误的近似值</li>
<li>耗空间极小，每个HyperLogLog key占用了12K的内存用于标记基数</li>
<li>pfadd命令不是一次性分配12K内存使用，会随着基数的增加内存而增大</li>
<li>pfmerge命令合并后占用的存储空间为12K，无论合并之前数据量多少</li>
</ul>
<hr>
<h3 id="geo">GEO</h3>
<blockquote>
<p>简介</p>
</blockquote>
<p>GEO可以用于存储位置信息。</p>
<blockquote>
<p>操作</p>
</blockquote>
<pre><code>geoadd key longitude latitude member [longitude latitude member...]			  //添加坐标点
geopos key member [member...]		//获取坐标点
geodist key member1 member2 [unit]	//计算坐标点距离
georadius key longitude latitude radius m|km|ft|mi [withcoord] [withdist] [withhash] [count count]			  //根据坐标求范围内的数据
georadiusbymember key member radius m|km|ft|mi [withcoord] [withdist] [withhash] [count count]			  //根据点求范围内的数据
geohash key member [member...]		//获取指定点对应的坐标hash值

</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Redis基础]]></title>
        <id>https://Squid-dot.github.io/post/redis-ji-chu/</id>
        <link href="https://Squid-dot.github.io/post/redis-ji-chu/">
        </link>
        <updated>2020-03-06T13:17:28.000Z</updated>
        <content type="html"><![CDATA[<h1 id="redis基础">Redis基础</h1>
<h2 id="redis简介">Redis简介</h2>
<h3 id="nosql">NoSQL</h3>
<p>NoSQL：即Not-OnlySQL（泛指非关系型的数据库），作为关系型数据库的补充。</p>
<p>作用：应对基于海量用户和海量数据前提下的数据处理问题。</p>
<p>特征：</p>
<ul>
<li>可扩容，可伸缩</li>
<li>大数据量下高性能</li>
<li>灵活的数据模型</li>
<li>高可用</li>
</ul>
<hr>
<h3 id="redis概念">Redis概念</h3>
<p><strong>Redis</strong>是用C语言开发的一个开源的高性能键值对（key-value）数据库。</p>
<p>特征：</p>
<ol>
<li>数据间没有必然的关联关系</li>
<li>内部采用<strong>单线程</strong>机制进行工作</li>
<li>高性能</li>
<li>多数据类型支持</li>
<li>持久化支持</li>
</ol>
<hr>
<h2 id="redis数据">Redis数据</h2>
<h3 id="redis数据存储格式">Redis数据存储格式</h3>
<p>Redis自身的是一个Map，所有的数据以键值对的方式存储。</p>
<blockquote>
<p>key的设置约定</p>
</blockquote>
<p>表名：主键名：主键值：字段名</p>
<hr>
<h3 id="数据类型">数据类型</h3>
<blockquote>
<p>string类型</p>
</blockquote>
<ul>
<li>存储的数据：单个数据，最简单的数据存储类型，也是最常用的数据存储类型</li>
<li>存储数据的格式：一个存储空间保存一个数据</li>
<li>存储内容：通常使用字符串，如果字符串以整数的形式是展示，可以作为数字操作使用</li>
</ul>
<blockquote>
<p>hash类型</p>
</blockquote>
<ul>
<li>存储需求：对一系列存储的数据进行编组，方便管理，典型应用存储对象信息</li>
<li>需要的存储结构：一个存储空间保存多个键值对数据</li>
<li>hash：底层使用哈希表结构实现数据存储</li>
</ul>
<blockquote>
<p>list类型</p>
</blockquote>
<ul>
<li>存储需求：存储多个数据，并对数据进入存储空间的顺序进行区分</li>
<li>需要的存储结构：一个存储空间保存多个数据，且通过数据可以体现进入顺序</li>
<li>list：保存多个数据，底层使用双向链表存储结构实现</li>
</ul>
<blockquote>
<p>set类型</p>
</blockquote>
<ul>
<li>存储需求：存储大量的数据，在查询方面提供跟高的效率</li>
<li>需要的存储结构：能够保存大量的数据，高效的内部存储机制，便于查询</li>
<li>set：与hash的存储结构完全相同，将值存储于hash的key中，hash的value中存储nil，并且值不允许重复</li>
</ul>
<blockquote>
<p>sorted_set类型</p>
</blockquote>
<ul>
<li>存储需求：数据排序有利于数据的有效展示，需要提供一种可以根据自身特征进行排序的方式</li>
<li>需要的存储结构：新的存储模型，可以保存可排序的数据</li>
<li>sorted_set：在set的存储结构基础上添加可排序字段</li>
</ul>
<hr>
<h2 id="redis的基本操作">Redis的基本操作</h2>
<h3 id="string类型">String类型</h3>
<blockquote>
<p>信息添加</p>
</blockquote>
<ul>
<li>
<p>功能：设置 key value</p>
</li>
<li>
<p>命令</p>
</li>
</ul>
<pre><code>set key value
</code></pre>
<blockquote>
<p>信息查询</p>
</blockquote>
<ul>
<li>
<p>功能：根据 key 查询 value</p>
</li>
<li>
<p>命令</p>
</li>
</ul>
<pre><code>get key
</code></pre>
<blockquote>
<p>信息删除</p>
</blockquote>
<ul>
<li>
<p>功能：删除 key value</p>
</li>
<li>
<p>命令</p>
</li>
</ul>
<pre><code>del key
</code></pre>
<blockquote>
<p>添加/修改多个数据</p>
</blockquote>
<pre><code>mset key1 value1 key2 value2 ...
</code></pre>
<blockquote>
<p>获取多个数据</p>
</blockquote>
<pre><code>mget key1 key2 ...
</code></pre>
<blockquote>
<p>获取数据字符个数（字符串长度）</p>
</blockquote>
<pre><code>strlen key
</code></pre>
<blockquote>
<p>追加信息到原始信息后</p>
</blockquote>
<pre><code>append key value
</code></pre>
<blockquote>
<p>设置数值数据增加/减少指定范围的值</p>
</blockquote>
<pre><code>incr/decr key
incrby/decrby key integerNumber
incrbyfloat key floatNumber
</code></pre>
<blockquote>
<p>设置指定时常的生命周期的数据</p>
</blockquote>
<pre><code>setex key seconds value		
psetex key milliseconds		
</code></pre>
<p><strong>注意事项：</strong></p>
<ul>
<li>数据操作返回值
<ul>
<li>表示数据运行结果是否成功，成功：(integer)1、失败：(integer)0</li>
<li>表示运行结果值，如：(integer)3</li>
</ul>
</li>
<li>未获取到数据
<ul>
<li>(nil) 等同于null</li>
</ul>
</li>
<li>数据最大存储量：512MB</li>
</ul>
<hr>
<h3 id="hash类型">Hash类型</h3>
<blockquote>
<p>添加/修改数据</p>
</blockquote>
<pre><code>hset key field value
hsetnx key field value 		//如果库中存在key则不添加
</code></pre>
<blockquote>
<p>获取数据</p>
</blockquote>
<pre><code>hget key field
hgetall key			//获取全部
</code></pre>
<blockquote>
<p>删除数据</p>
</blockquote>
<pre><code>hdel key field1 [field2]
</code></pre>
<blockquote>
<p>添加/修改多个数据</p>
</blockquote>
<pre><code>hmset key field1 value1 field2 value2 ...
</code></pre>
<blockquote>
<p>获取数据</p>
</blockquote>
<pre><code>hmget key field1 field2 ...
</code></pre>
<blockquote>
<p>获取哈希表中的字数</p>
</blockquote>
<pre><code>hlen key
</code></pre>
<blockquote>
<p>获取哈希表中是否存在指定字段</p>
</blockquote>
<pre><code>hexists key field
</code></pre>
<blockquote>
<p>获取哈希表中所有的字段名或字段值</p>
</blockquote>
<pre><code>hkeys key
hvals key

</code></pre>
<blockquote>
<p>设置指定字段的数值数据增加指定范围的值</p>
</blockquote>
<pre><code>hincrby key field integerNumber
hincrbyfloat key field floatNumber

</code></pre>
<p><strong>注意事项：</strong></p>
<ul>
<li>hash类型下的value只能存储字符串，不允许存储其他数据类型</li>
<li>每个hash可以存储2<sup>32</sup>-1个键值对</li>
<li>hash类型十分贴近对象的数据存储形式，并且可以灵活的添加或删除对象属性，但hash设计初衷并不是为了存储大量对象，所以不可滥用，更不可将hash作为对象列表使用</li>
<li>hgetall可以获取全部属性，但是如果内部field过多，会导致遍历整体数据效率变低，成为数据访问瓶颈</li>
</ul>
<hr>
<h3 id="list类型">List类型</h3>
<blockquote>
<p>添加/修改数据</p>
</blockquote>
<pre><code>lpush key value1 [value2] ...	//左进入
rpush key value1 [value2] ...	//右进入

</code></pre>
<blockquote>
<p>获取数据</p>
</blockquote>
<pre><code>lrange key start stop
lindex key index
llen key

</code></pre>
<blockquote>
<p>获取并移除数据</p>
</blockquote>
<pre><code>lpop key
rpop key

</code></pre>
<blockquote>
<p>规定时间内获取并移除数据</p>
</blockquote>
<pre><code>blpop key1 [key2] timeout
brpop key1 [key2] timeout

</code></pre>
<blockquote>
<p>移除指定数据</p>
</blockquote>
<pre><code>lrem key count value

</code></pre>
<p><strong>注意事项：</strong></p>
<ul>
<li>list中保存的数据都是string类型的，最多容纳2<sup>32</sup>-1条数据</li>
<li>list具有索引的概念，但是操作时通常以队列的形式进行出入队操作，或以栈形式进行出入栈操作</li>
<li>获取全部数据操作的结束索引设置为-1</li>
<li>list可以对数据进行分页操作，通常第一页信息来自于list，第二页及更多信息通过数据库加载</li>
</ul>
<hr>
<h3 id="set类型">Set类型</h3>
<blockquote>
<p>添加数据</p>
</blockquote>
<pre><code>sadd key member1 [member2]

</code></pre>
<blockquote>
<p>获取全部数据</p>
</blockquote>
<pre><code>semebers key

</code></pre>
<blockquote>
<p>删除数据</p>
</blockquote>
<pre><code>srem key member1 [member2]

</code></pre>
<blockquote>
<p>获取集合数据总量</p>
</blockquote>
<pre><code>scard key

</code></pre>
<blockquote>
<p>判断集合中是否包含指定数据</p>
</blockquote>
<pre><code>sismember key member

</code></pre>
<blockquote>
<p>随机获取集合中指定数量的数据</p>
</blockquote>
<pre><code>srandmember key [count]

</code></pre>
<blockquote>
<p>随机获取集合中的某个数据并将该数据移出集合</p>
</blockquote>
<pre><code>spop key [count]

</code></pre>
<blockquote>
<p>求两个集合的交、并、差集</p>
</blockquote>
<pre><code>sinter key1 [key...]
sunion key1 [key...]
sdiff key1 [key...]

</code></pre>
<blockquote>
<p>求两个集合的交、并、差集并存到指定集合中</p>
</blockquote>
<pre><code>sinterstore destination key1 [key...]
sunionstore destination key1 [key...]
sdiffstore destination key1 [key...]

</code></pre>
<blockquote>
<p>将指定数据从原始集合中移动到目标集合中</p>
</blockquote>
<pre><code>smove source destination member

</code></pre>
<p><strong>注意事项：</strong></p>
<ul>
<li>set类型不允许数据重复，如果添加的数据在set中已存在，将只保留一份</li>
<li>set虽然与hash的存储结构相同，但是无法启用hash中存储值的空间</li>
</ul>
<hr>
<h3 id="sorted_set类型">Sorted_set类型</h3>
<blockquote>
<p>添加数据</p>
</blockquote>
<pre><code>zadd key score1 member1 [score member ...]

</code></pre>
<blockquote>
<p>获取全部数据</p>
</blockquote>
<pre><code>zrange key start stop [WITHSCORES]
zrevrange key start stop [WITHSCORES]

</code></pre>
<blockquote>
<p>删除数据</p>
</blockquote>
<pre><code>zrem key member [member ...]

</code></pre>
<blockquote>
<p>按条件获取数据</p>
</blockquote>
<pre><code>zrangebyrescore key min max [WITHSCORES] [LIMIT]
zrevrangebyscore key min max [WITHSCORES] [LIMIT]

</code></pre>
<blockquote>
<p>条件删除数据</p>
</blockquote>
<pre><code>zremrangebyrank key start stop
zremrangebyscore key min max

</code></pre>
<blockquote>
<p>获取集合数据总量</p>
</blockquote>
<pre><code>zcard key
zcount key min max

</code></pre>
<blockquote>
<p>集合交、并操作</p>
</blockquote>
<pre><code>zinterstore destination numkeys key [key ...]
zunionstore destination numkeys key [key ...]

</code></pre>
<blockquote>
<p>获取数据对应的索引（排名）</p>
</blockquote>
<pre><code>zrank key member
zrevrank key member

</code></pre>
<blockquote>
<p>score值获取与修改</p>
</blockquote>
<pre><code>zscore key member
zincrby key increment 

</code></pre>
<p><strong>注意事项：</strong></p>
<ul>
<li>score保存的数据存储空间是64位</li>
<li>score保存的数据也可以是一个双精度的double值，基于双精度浮点数的特征，可能会丢失精度，使用时需要谨慎</li>
<li>sorted_set底层存储结构还是基于set的，因此数据不允许重复，如果重复添加数据，score值将被覆盖，保留最后一次修改的结果</li>
</ul>
<hr>
<h2 id="通用命令">通用命令</h2>
<h3 id="key的基本操作">key的基本操作</h3>
<blockquote>
<p>删除指定key</p>
</blockquote>
<pre><code>del key

</code></pre>
<blockquote>
<p>获取key是否存在</p>
</blockquote>
<pre><code>exists key

</code></pre>
<blockquote>
<p>获取key的类型</p>
</blockquote>
<pre><code>type key

</code></pre>
<blockquote>
<p>查询key</p>
</blockquote>
<pre><code>keys pattern
* 匹配任意数量的任意符号
? 匹配任意一个符号
[] 匹配一个指定的符号

</code></pre>
<blockquote>
<p>改变key的名字</p>
</blockquote>
<pre><code>rename key newkey
renamenx key newkey

</code></pre>
<blockquote>
<p>对所有key排序</p>
</blockquote>
<pre><code>sort

</code></pre>
<p><strong>时效性操作：</strong></p>
<blockquote>
<p>为指定的key设置有效期</p>
</blockquote>
<pre><code>expire key seconds
pexpire key milliseconds
expireat key timestamp
pexpireat key milliseconds

</code></pre>
<blockquote>
<p>获取key的有效时间</p>
</blockquote>
<pre><code>ttl key
pttl key

</code></pre>
<blockquote>
<p>将key从时效性转换为永久性</p>
</blockquote>
<pre><code>persist key

</code></pre>
<hr>
<h3 id="数据库基本操作">数据库基本操作</h3>
<ul>
<li>redis为每个服务提供有16个数据库，编号从0-15</li>
<li>每个数据库之间的数据相互独立</li>
</ul>
<blockquote>
<p>切换数据库</p>
</blockquote>
<pre><code>select index

</code></pre>
<blockquote>
<p>数据移动</p>
</blockquote>
<pre><code>move key db

</code></pre>
<blockquote>
<p>数据清除</p>
</blockquote>
<pre><code>dbsize		//查看数据总量
flushdb		//清除当前数据
flushall	//清除全部数据

</code></pre>
<blockquote>
<p>其他操作</p>
</blockquote>
<pre><code>quit
ping
echo message

</code></pre>
<hr>
<h2 id="jdies">Jdies</h2>
<blockquote>
<p>Jedis简介</p>
</blockquote>
<p>Jedis是Java语言连接redis服务。</p>
<hr>
<h3 id="使用方式">使用方式</h3>
<blockquote>
<p>在pom文件中导入jedis的依赖。</p>
</blockquote>
<pre><code class="language-xml">        &lt;!-- jedis --&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;redis.clients&lt;/groupId&gt;
            &lt;artifactId&gt;jedis&lt;/artifactId&gt;
            &lt;version&gt;3.2.0&lt;/version&gt;
        &lt;/dependency&gt;

</code></pre>
<blockquote>
<p>在类中进行连接</p>
</blockquote>
<pre><code class="language-java">        //1.连接redis
        Jedis jedis = new Jedis(&quot;127.0.0.1&quot;, 6379);
        //2.操作redis
        jedis.set(&quot;name&quot;,&quot;squid&quot;);//Jedis中的方法名与redis中命令名完全一致
        String name = jedis.get(&quot;name&quot;);
        System.out.println(name);
        //3.断开连接
        jedis.close();

</code></pre>
<p>**注意：**从redis中取出的所有数据类型与java中的数据类型一一对应。</p>
<hr>
<h3 id="jedis工具类">Jedis工具类</h3>
<pre><code class="language-java">public class JedisUtil {
    private static JedisPool jedisPool = null;
    private static Integer port = null;
    private static Integer maxTotal = null;
    private static Integer maxIdle = null;

    static{
        ResourceBundle resourceBundle = ResourceBundle.getBundle(&quot;redis&quot;);//获取配置文件
        String host = resourceBundle.getString(&quot;redis.host&quot;);
        port = Integer.valueOf(resourceBundle.getString(&quot;redis.port&quot;));
        maxTotal = Integer.valueOf(resourceBundle.getString(&quot;redis.maxTotal&quot;));
        maxIdle = Integer.valueOf(resourceBundle.getString(&quot;redis.maxIdle&quot;));

        JedisPoolConfig jedisPoolConfig = new JedisPoolConfig();
        jedisPoolConfig.setMaxTotal(maxTotal);//最大连接数
        jedisPoolConfig.setMaxIdle(maxIdle);//活动连接数
        jedisPool = new JedisPool(jedisPoolConfig,host,port);
    }
    public static Jedis getJedis(){
        return jedisPool.getResource();
    }
}

</code></pre>
]]></content>
    </entry>
</feed>